mode: category
type: xlnet_fc
train path: ./task2/ACSA/processed/train_xlnet.npz
val path: ./task2/ACSA/processed/val_xlnet.npz
./task2/ACSA/processed/train_xlnet.npz
model save path: ./task2/ACSA/checkpoints/xlnet_fc_all.pth
[epoch  0] [step  10] train_loss: 0.8502 train_acc: 0.3381 val_loss: 0.3962 val_acc: 0.4366 f1: 0.2133
[epoch  0] [step  20] train_loss: 0.6612 train_acc: 0.3542 val_loss: 0.3791 val_acc: 0.4366 f1: 0.2027
[epoch  0] [step  30] train_loss: 0.5796 train_acc: 0.3599 val_loss: 0.3649 val_acc: 0.3002 f1: 0.2027
[epoch  0] [step  40] train_loss: 0.5323 train_acc: 0.3720 val_loss: 0.3418 val_acc: 0.4539 f1: 0.3180
[epoch  0] [step  50] train_loss: 0.5022 train_acc: 0.3756 val_loss: 0.3251 val_acc: 0.4399 f1: 0.4235
[epoch  0] [step  60] train_loss: 0.4798 train_acc: 0.3847 val_loss: 0.3181 val_acc: 0.4472 f1: 0.2332
[epoch  0] [step  70] train_loss: 0.4633 train_acc: 0.3825 val_loss: 0.3101 val_acc: 0.4802 f1: 0.4218
[epoch  0] [step  80] train_loss: 0.4496 train_acc: 0.3927 val_loss: 0.3304 val_acc: 0.4371 f1: 0.4105
[epoch  0] [step  90] train_loss: 0.4357 train_acc: 0.4018 val_loss: 0.3175 val_acc: 0.4405 f1: 0.4162
[epoch  0] [step 100] train_loss: 0.4243 train_acc: 0.4158 val_loss: 0.2659 val_acc: 0.6104 f1: 0.5841
[epoch  0] [step 110] train_loss: 0.4147 train_acc: 0.4279 val_loss: 0.2876 val_acc: 0.5657 f1: 0.5041
[epoch  0] [step 120] train_loss: 0.4054 train_acc: 0.4403 val_loss: 0.2435 val_acc: 0.6423 f1: 0.6112
[epoch  0] [step 130] train_loss: 0.3955 train_acc: 0.4552 val_loss: 0.2544 val_acc: 0.6579 f1: 0.6242
[epoch  0] [step 140] train_loss: 0.3868 train_acc: 0.4685 val_loss: 0.2711 val_acc: 0.6451 f1: 0.5830
[epoch  0] [step 150] train_loss: 0.3792 train_acc: 0.4783 val_loss: 0.2409 val_acc: 0.6607 f1: 0.6305
[epoch  0] [step 160] train_loss: 0.3747 train_acc: 0.4845 val_loss: 0.2363 val_acc: 0.6590 f1: 0.6157
[epoch  0] [step 170] train_loss: 0.3678 train_acc: 0.4943 val_loss: 0.2248 val_acc: 0.6747 f1: 0.6534
[epoch  0] [step 180] train_loss: 0.3606 train_acc: 0.5041 val_loss: 0.2340 val_acc: 0.6395 f1: 0.6398
[epoch  0] [step 190] train_loss: 0.3552 train_acc: 0.5106 val_loss: 0.2266 val_acc: 0.6764 f1: 0.6694
[epoch  0] [step 200] train_loss: 0.3502 train_acc: 0.5182 val_loss: 0.2299 val_acc: 0.6836 f1: 0.6464
[epoch  0] [step 210] train_loss: 0.3465 train_acc: 0.5225 val_loss: 0.2657 val_acc: 0.6132 f1: 0.6134
[epoch  0] [step 220] train_loss: 0.3440 train_acc: 0.5243 val_loss: 0.2304 val_acc: 0.6657 f1: 0.6158
[epoch  0] [step 221] train_loss: 0.3437 train_acc: 0.5247 val_loss: 0.2321 val_acc: 0.6786 f1: 0.6562
positive -- correct: 296  predict: 522  real: 486  f1: 0.5873
negative -- correct: 377  predict: 546  real: 522  f1: 0.7060
neutral  -- correct: 537  predict: 721  real: 781  f1: 0.7150
best_epoch: 0  best_step: 190  best_f1: 0.6694
time: 253.3670s
[epoch  1] [step  10] train_loss: 0.2494 train_acc: 0.6619 val_loss: 0.2145 val_acc: 0.6831 f1: 0.6653
[epoch  1] [step  20] train_loss: 0.2568 train_acc: 0.6310 val_loss: 0.2276 val_acc: 0.6747 f1: 0.6384
[epoch  1] [step  30] train_loss: 0.2449 train_acc: 0.6552 val_loss: 0.2559 val_acc: 0.6752 f1: 0.6733
[epoch  1] [step  40] train_loss: 0.2419 train_acc: 0.6608 val_loss: 0.2117 val_acc: 0.7004 f1: 0.6797
[epoch  1] [step  50] train_loss: 0.2407 train_acc: 0.6636 val_loss: 0.2363 val_acc: 0.6540 f1: 0.6566
[epoch  1] [step  60] train_loss: 0.2373 train_acc: 0.6706 val_loss: 0.2168 val_acc: 0.6993 f1: 0.6807
[epoch  1] [step  70] train_loss: 0.2367 train_acc: 0.6695 val_loss: 0.2111 val_acc: 0.7071 f1: 0.6811
[epoch  1] [step  80] train_loss: 0.2391 train_acc: 0.6667 val_loss: 0.2045 val_acc: 0.7060 f1: 0.6994
[epoch  1] [step  90] train_loss: 0.2376 train_acc: 0.6686 val_loss: 0.2034 val_acc: 0.7132 f1: 0.7105
[epoch  1] [step 100] train_loss: 0.2364 train_acc: 0.6689 val_loss: 0.2108 val_acc: 0.7149 f1: 0.7056
[epoch  1] [step 110] train_loss: 0.2355 train_acc: 0.6717 val_loss: 0.1871 val_acc: 0.7345 f1: 0.7255
[epoch  1] [step 120] train_loss: 0.2336 train_acc: 0.6733 val_loss: 0.1915 val_acc: 0.7367 f1: 0.7210
[epoch  1] [step 130] train_loss: 0.2306 train_acc: 0.6777 val_loss: 0.1838 val_acc: 0.7524 f1: 0.7439
[epoch  1] [step 140] train_loss: 0.2314 train_acc: 0.6782 val_loss: 0.1871 val_acc: 0.7479 f1: 0.7416
[epoch  1] [step 150] train_loss: 0.2306 train_acc: 0.6792 val_loss: 0.1927 val_acc: 0.7457 f1: 0.7314
[epoch  1] [step 160] train_loss: 0.2302 train_acc: 0.6815 val_loss: 0.1842 val_acc: 0.7451 f1: 0.7365
[epoch  1] [step 170] train_loss: 0.2276 train_acc: 0.6853 val_loss: 0.1792 val_acc: 0.7580 f1: 0.7530
[epoch  1] [step 180] train_loss: 0.2264 train_acc: 0.6866 val_loss: 0.1736 val_acc: 0.7680 f1: 0.7556
[epoch  1] [step 190] train_loss: 0.2244 train_acc: 0.6900 val_loss: 0.1765 val_acc: 0.7608 f1: 0.7510
[epoch  1] [step 200] train_loss: 0.2246 train_acc: 0.6901 val_loss: 0.1754 val_acc: 0.7630 f1: 0.7570
[epoch  1] [step 210] train_loss: 0.2240 train_acc: 0.6908 val_loss: 0.1670 val_acc: 0.7619 f1: 0.7515
[epoch  1] [step 220] train_loss: 0.2224 train_acc: 0.6932 val_loss: 0.1701 val_acc: 0.7647 f1: 0.7535
[epoch  1] [step 221] train_loss: 0.2222 train_acc: 0.6935 val_loss: 0.1732 val_acc: 0.7624 f1: 0.7508
positive -- correct: 364  predict: 539  real: 486  f1: 0.7102
negative -- correct: 369  predict: 443  real: 522  f1: 0.7648
neutral  -- correct: 632  predict: 807  real: 781  f1: 0.7960
best_epoch: 1  best_step: 200  best_f1: 0.7570
time: 248.8608s
[epoch  2] [step  10] train_loss: 0.1440 train_acc: 0.7983 val_loss: 0.2117 val_acc: 0.7490 f1: 0.7488
[epoch  2] [step  20] train_loss: 0.1647 train_acc: 0.7812 val_loss: 0.1811 val_acc: 0.7507 f1: 0.7479
[epoch  2] [step  30] train_loss: 0.1694 train_acc: 0.7802 val_loss: 0.1931 val_acc: 0.7451 f1: 0.7326
[epoch  2] [step  40] train_loss: 0.1713 train_acc: 0.7774 val_loss: 0.2206 val_acc: 0.7395 f1: 0.7256
[epoch  2] [step  50] train_loss: 0.1824 train_acc: 0.7721 val_loss: 0.2318 val_acc: 0.7211 f1: 0.7213
[epoch  2] [step  60] train_loss: 0.1821 train_acc: 0.7710 val_loss: 0.1812 val_acc: 0.7652 f1: 0.7612
[epoch  2] [step  70] train_loss: 0.1810 train_acc: 0.7698 val_loss: 0.1750 val_acc: 0.7697 f1: 0.7633
[epoch  2] [step  80] train_loss: 0.1764 train_acc: 0.7731 val_loss: 0.1813 val_acc: 0.7697 f1: 0.7619
[epoch  2] [step  90] train_loss: 0.1736 train_acc: 0.7747 val_loss: 0.1824 val_acc: 0.7686 f1: 0.7577
[epoch  2] [step 100] train_loss: 0.1727 train_acc: 0.7735 val_loss: 0.1776 val_acc: 0.7608 f1: 0.7508
[epoch  2] [step 110] train_loss: 0.1730 train_acc: 0.7717 val_loss: 0.1851 val_acc: 0.7529 f1: 0.7484
[epoch  2] [step 120] train_loss: 0.1722 train_acc: 0.7735 val_loss: 0.1878 val_acc: 0.7608 f1: 0.7589
[epoch  2] [step 130] train_loss: 0.1719 train_acc: 0.7750 val_loss: 0.1678 val_acc: 0.7854 f1: 0.7774
[epoch  2] [step 140] train_loss: 0.1714 train_acc: 0.7762 val_loss: 0.1662 val_acc: 0.7742 f1: 0.7704
[epoch  2] [step 150] train_loss: 0.1719 train_acc: 0.7752 val_loss: 0.1546 val_acc: 0.7909 f1: 0.7860
[epoch  2] [step 160] train_loss: 0.1720 train_acc: 0.7741 val_loss: 0.1579 val_acc: 0.7909 f1: 0.7840
[epoch  2] [step 170] train_loss: 0.1697 train_acc: 0.7778 val_loss: 0.1704 val_acc: 0.7753 f1: 0.7732
[epoch  2] [step 180] train_loss: 0.1692 train_acc: 0.7787 val_loss: 0.1616 val_acc: 0.7837 f1: 0.7781
[epoch  2] [step 190] train_loss: 0.1686 train_acc: 0.7793 val_loss: 0.1677 val_acc: 0.7781 f1: 0.7770
[epoch  2] [step 200] train_loss: 0.1678 train_acc: 0.7803 val_loss: 0.1519 val_acc: 0.8038 f1: 0.7962
[epoch  2] [step 210] train_loss: 0.1672 train_acc: 0.7808 val_loss: 0.1514 val_acc: 0.8044 f1: 0.8000
[epoch  2] [step 220] train_loss: 0.1660 train_acc: 0.7832 val_loss: 0.1611 val_acc: 0.7887 f1: 0.7823
[epoch  2] [step 221] train_loss: 0.1660 train_acc: 0.7832 val_loss: 0.1631 val_acc: 0.7893 f1: 0.7847
positive -- correct: 383  predict: 520  real: 486  f1: 0.7614
negative -- correct: 409  predict: 487  real: 522  f1: 0.8107
neutral  -- correct: 647  predict: 782  real: 781  f1: 0.8279
best_epoch: 2  best_step: 210  best_f1: 0.8000
time: 244.7002s
[epoch  3] [step  10] train_loss: 0.1157 train_acc: 0.8665 val_loss: 0.1624 val_acc: 0.7999 f1: 0.7913
[epoch  3] [step  20] train_loss: 0.1186 train_acc: 0.8601 val_loss: 0.1759 val_acc: 0.7854 f1: 0.7766
[epoch  3] [step  30] train_loss: 0.1271 train_acc: 0.8407 val_loss: 0.1626 val_acc: 0.7909 f1: 0.7857
[epoch  3] [step  40] train_loss: 0.1286 train_acc: 0.8354 val_loss: 0.1720 val_acc: 0.7893 f1: 0.7841
[epoch  3] [step  50] train_loss: 0.1304 train_acc: 0.8352 val_loss: 0.2178 val_acc: 0.7775 f1: 0.7764
[epoch  3] [step  60] train_loss: 0.1334 train_acc: 0.8284 val_loss: 0.1703 val_acc: 0.7904 f1: 0.7820
[epoch  3] [step  70] train_loss: 0.1347 train_acc: 0.8288 val_loss: 0.1608 val_acc: 0.7960 f1: 0.7910
[epoch  3] [step  80] train_loss: 0.1332 train_acc: 0.8306 val_loss: 0.1576 val_acc: 0.7977 f1: 0.7934
[epoch  3] [step  90] train_loss: 0.1312 train_acc: 0.8328 val_loss: 0.1685 val_acc: 0.7993 f1: 0.7922
[epoch  3] [step 100] train_loss: 0.1312 train_acc: 0.8308 val_loss: 0.2007 val_acc: 0.7904 f1: 0.7897
[epoch  3] [step 110] train_loss: 0.1285 train_acc: 0.8331 val_loss: 0.1795 val_acc: 0.7965 f1: 0.7911
[epoch  3] [step 120] train_loss: 0.1279 train_acc: 0.8332 val_loss: 0.1672 val_acc: 0.7960 f1: 0.7923
[epoch  3] [step 130] train_loss: 0.1268 train_acc: 0.8352 val_loss: 0.1693 val_acc: 0.7932 f1: 0.7898
[epoch  3] [step 140] train_loss: 0.1261 train_acc: 0.8362 val_loss: 0.1782 val_acc: 0.7937 f1: 0.7910
[epoch  3] [step 150] train_loss: 0.1260 train_acc: 0.8359 val_loss: 0.1644 val_acc: 0.7786 f1: 0.7722
[epoch  3] [step 160] train_loss: 0.1257 train_acc: 0.8364 val_loss: 0.1671 val_acc: 0.7898 f1: 0.7864
[epoch  3] [step 170] train_loss: 0.1257 train_acc: 0.8364 val_loss: 0.1728 val_acc: 0.7915 f1: 0.7890
[epoch  3] [step 180] train_loss: 0.1262 train_acc: 0.8348 val_loss: 0.1747 val_acc: 0.7865 f1: 0.7787
[epoch  3] [step 190] train_loss: 0.1259 train_acc: 0.8356 val_loss: 0.2054 val_acc: 0.7731 f1: 0.7732
[epoch  3] [step 200] train_loss: 0.1253 train_acc: 0.8358 val_loss: 0.1820 val_acc: 0.7943 f1: 0.7842
[epoch  3] [step 210] train_loss: 0.1266 train_acc: 0.8343 val_loss: 0.1968 val_acc: 0.7921 f1: 0.7901
[epoch  3] [step 220] train_loss: 0.1267 train_acc: 0.8344 val_loss: 0.1544 val_acc: 0.7993 f1: 0.7927
[epoch  3] [step 221] train_loss: 0.1268 train_acc: 0.8343 val_loss: 0.1548 val_acc: 0.8004 f1: 0.7948
positive -- correct: 383  predict: 520  real: 486  f1: 0.7614
negative -- correct: 409  predict: 487  real: 522  f1: 0.8107
neutral  -- correct: 647  predict: 782  real: 781  f1: 0.8279
best_epoch: 2  best_step: 210  best_f1: 0.8000
time: 225.3889s
[epoch  4] [step  10] train_loss: 0.0816 train_acc: 0.8892 val_loss: 0.1857 val_acc: 0.7943 f1: 0.7898
[epoch  4] [step  20] train_loss: 0.0804 train_acc: 0.8958 val_loss: 0.2167 val_acc: 0.7977 f1: 0.7943
[epoch  4] [step  30] train_loss: 0.0870 train_acc: 0.8861 val_loss: 0.2026 val_acc: 0.8027 f1: 0.7961
[epoch  4] [step  40] train_loss: 0.0894 train_acc: 0.8849 val_loss: 0.1692 val_acc: 0.8044 f1: 0.8014
[epoch  4] [step  50] train_loss: 0.0893 train_acc: 0.8824 val_loss: 0.1748 val_acc: 0.8066 f1: 0.8019
[epoch  4] [step  60] train_loss: 0.0904 train_acc: 0.8817 val_loss: 0.1885 val_acc: 0.8055 f1: 0.8005
[epoch  4] [step  70] train_loss: 0.0923 train_acc: 0.8785 val_loss: 0.2001 val_acc: 0.7898 f1: 0.7874
[epoch  4] [step  80] train_loss: 0.0931 train_acc: 0.8789 val_loss: 0.1800 val_acc: 0.7971 f1: 0.7880
[epoch  4] [step  90] train_loss: 0.0920 train_acc: 0.8808 val_loss: 0.1972 val_acc: 0.7982 f1: 0.7961
[epoch  4] [step 100] train_loss: 0.0904 train_acc: 0.8827 val_loss: 0.1889 val_acc: 0.8111 f1: 0.8050
[epoch  4] [step 110] train_loss: 0.0896 train_acc: 0.8834 val_loss: 0.1858 val_acc: 0.8060 f1: 0.8018
[epoch  4] [step 120] train_loss: 0.0943 train_acc: 0.8765 val_loss: 0.1625 val_acc: 0.7949 f1: 0.7899
[epoch  4] [step 130] train_loss: 0.0932 train_acc: 0.8783 val_loss: 0.1681 val_acc: 0.8004 f1: 0.7961
[epoch  4] [step 140] train_loss: 0.0945 train_acc: 0.8770 val_loss: 0.1903 val_acc: 0.8044 f1: 0.8008
[epoch  4] [step 150] train_loss: 0.0952 train_acc: 0.8764 val_loss: 0.1810 val_acc: 0.7915 f1: 0.7850
[epoch  4] [step 160] train_loss: 0.0954 train_acc: 0.8760 val_loss: 0.1691 val_acc: 0.8021 f1: 0.7984
[epoch  4] [step 170] train_loss: 0.0948 train_acc: 0.8768 val_loss: 0.1864 val_acc: 0.8055 f1: 0.7992
[epoch  4] [step 180] train_loss: 0.0950 train_acc: 0.8767 val_loss: 0.1751 val_acc: 0.8049 f1: 0.8003
[epoch  4] [step 190] train_loss: 0.0946 train_acc: 0.8768 val_loss: 0.1938 val_acc: 0.7993 f1: 0.7969
[epoch  4] [step 200] train_loss: 0.0945 train_acc: 0.8770 val_loss: 0.1963 val_acc: 0.7921 f1: 0.7879
[epoch  4] [step 210] train_loss: 0.0944 train_acc: 0.8777 val_loss: 0.1672 val_acc: 0.8072 f1: 0.8026
[epoch  4] [step 220] train_loss: 0.0939 train_acc: 0.8792 val_loss: 0.1717 val_acc: 0.8178 f1: 0.8115
[epoch  4] [step 221] train_loss: 0.0940 train_acc: 0.8793 val_loss: 0.1713 val_acc: 0.8183 f1: 0.8129
positive -- correct: 376  predict: 489  real: 486  f1: 0.7713
negative -- correct: 425  predict: 511  real: 522  f1: 0.8228
neutral  -- correct: 663  predict: 789  real: 781  f1: 0.8446
best_epoch: 4  best_step: 221  best_f1: 0.8129
time: 236.3570s
[epoch  5] [step  10] train_loss: 0.0619 train_acc: 0.9347 val_loss: 0.1820 val_acc: 0.8144 f1: 0.8099
[epoch  5] [step  20] train_loss: 0.0688 train_acc: 0.9122 val_loss: 0.2134 val_acc: 0.8027 f1: 0.8006
[epoch  5] [step  30] train_loss: 0.0719 train_acc: 0.9073 val_loss: 0.1723 val_acc: 0.8228 f1: 0.8184
[epoch  5] [step  40] train_loss: 0.0701 train_acc: 0.9101 val_loss: 0.1837 val_acc: 0.8178 f1: 0.8153
[epoch  5] [step  50] train_loss: 0.0685 train_acc: 0.9124 val_loss: 0.1903 val_acc: 0.8099 f1: 0.8077
[epoch  5] [step  60] train_loss: 0.0659 train_acc: 0.9160 val_loss: 0.1857 val_acc: 0.8099 f1: 0.8039
[epoch  5] [step  70] train_loss: 0.0681 train_acc: 0.9124 val_loss: 0.1930 val_acc: 0.8099 f1: 0.8075
[epoch  5] [step  80] train_loss: 0.0681 train_acc: 0.9124 val_loss: 0.1912 val_acc: 0.8139 f1: 0.8096
[epoch  5] [step  90] train_loss: 0.0671 train_acc: 0.9141 val_loss: 0.2002 val_acc: 0.8099 f1: 0.8019
[epoch  5] [step 100] train_loss: 0.0666 train_acc: 0.9155 val_loss: 0.2136 val_acc: 0.8116 f1: 0.8093
[epoch  5] [step 110] train_loss: 0.0660 train_acc: 0.9175 val_loss: 0.1988 val_acc: 0.8262 f1: 0.8210
[epoch  5] [step 120] train_loss: 0.0655 train_acc: 0.9176 val_loss: 0.2077 val_acc: 0.8139 f1: 0.8115
[epoch  5] [step 130] train_loss: 0.0656 train_acc: 0.9172 val_loss: 0.1958 val_acc: 0.8172 f1: 0.8125
[epoch  5] [step 140] train_loss: 0.0657 train_acc: 0.9169 val_loss: 0.1927 val_acc: 0.8077 f1: 0.8048
[epoch  5] [step 150] train_loss: 0.0668 train_acc: 0.9164 val_loss: 0.1935 val_acc: 0.8004 f1: 0.7971
[epoch  5] [step 160] train_loss: 0.0653 train_acc: 0.9191 val_loss: 0.2048 val_acc: 0.8178 f1: 0.8117
[epoch  5] [step 170] train_loss: 0.0652 train_acc: 0.9194 val_loss: 0.2114 val_acc: 0.8066 f1: 0.8029
[epoch  5] [step 180] train_loss: 0.0656 train_acc: 0.9190 val_loss: 0.1900 val_acc: 0.8105 f1: 0.8055
[epoch  5] [step 190] train_loss: 0.0661 train_acc: 0.9187 val_loss: 0.1866 val_acc: 0.8094 f1: 0.8044
[epoch  5] [step 200] train_loss: 0.0669 train_acc: 0.9170 val_loss: 0.1910 val_acc: 0.8083 f1: 0.8039
[epoch  5] [step 210] train_loss: 0.0663 train_acc: 0.9180 val_loss: 0.1942 val_acc: 0.8105 f1: 0.8033
[epoch  5] [step 220] train_loss: 0.0671 train_acc: 0.9174 val_loss: 0.2009 val_acc: 0.8083 f1: 0.8052
[epoch  5] [step 221] train_loss: 0.0670 train_acc: 0.9175 val_loss: 0.1941 val_acc: 0.8094 f1: 0.8059
positive -- correct: 379  predict: 477  real: 486  f1: 0.7871
negative -- correct: 424  predict: 505  real: 522  f1: 0.8257
neutral  -- correct: 675  predict: 807  real: 781  f1: 0.8501
best_epoch: 5  best_step: 110  best_f1: 0.8210
time: 240.1357s
[epoch  6] [step  10] train_loss: 0.0525 train_acc: 0.9403 val_loss: 0.2002 val_acc: 0.8088 f1: 0.8035
[epoch  6] [step  20] train_loss: 0.0511 train_acc: 0.9405 val_loss: 0.2169 val_acc: 0.8150 f1: 0.8112
[epoch  6] [step  30] train_loss: 0.0463 train_acc: 0.9446 val_loss: 0.2249 val_acc: 0.8172 f1: 0.8128
[epoch  6] [step  40] train_loss: 0.0418 train_acc: 0.9489 val_loss: 0.2562 val_acc: 0.8127 f1: 0.8075
[epoch  6] [step  50] train_loss: 0.0410 train_acc: 0.9504 val_loss: 0.2462 val_acc: 0.8133 f1: 0.8075
[epoch  6] [step  60] train_loss: 0.0435 train_acc: 0.9447 val_loss: 0.2551 val_acc: 0.8032 f1: 0.7985
[epoch  6] [step  70] train_loss: 0.0441 train_acc: 0.9428 val_loss: 0.2122 val_acc: 0.8105 f1: 0.8051
[epoch  6] [step  80] train_loss: 0.0426 train_acc: 0.9448 val_loss: 0.2229 val_acc: 0.8077 f1: 0.8026
[epoch  6] [step  90] train_loss: 0.0450 train_acc: 0.9454 val_loss: 0.2407 val_acc: 0.7993 f1: 0.7958
[epoch  6] [step 100] train_loss: 0.0452 train_acc: 0.9455 val_loss: 0.2069 val_acc: 0.8167 f1: 0.8115
[epoch  6] [step 110] train_loss: 0.0449 train_acc: 0.9462 val_loss: 0.2134 val_acc: 0.8105 f1: 0.8055
[epoch  6] [step 120] train_loss: 0.0451 train_acc: 0.9452 val_loss: 0.2239 val_acc: 0.8072 f1: 0.8026
[epoch  6] [step 130] train_loss: 0.0447 train_acc: 0.9458 val_loss: 0.2369 val_acc: 0.8099 f1: 0.8063
[epoch  6] [step 140] train_loss: 0.0446 train_acc: 0.9468 val_loss: 0.2237 val_acc: 0.8111 f1: 0.8049
[epoch  6] [step 150] train_loss: 0.0449 train_acc: 0.9462 val_loss: 0.2148 val_acc: 0.8161 f1: 0.8103
[epoch  6] [step 160] train_loss: 0.0460 train_acc: 0.9443 val_loss: 0.2082 val_acc: 0.8161 f1: 0.8116
[epoch  6] [step 170] train_loss: 0.0465 train_acc: 0.9433 val_loss: 0.2040 val_acc: 0.8133 f1: 0.8091
[epoch  6] [step 180] train_loss: 0.0468 train_acc: 0.9434 val_loss: 0.2094 val_acc: 0.8150 f1: 0.8118
[epoch  6] [step 190] train_loss: 0.0468 train_acc: 0.9436 val_loss: 0.2258 val_acc: 0.8195 f1: 0.8148
[epoch  6] [step 200] train_loss: 0.0466 train_acc: 0.9442 val_loss: 0.2184 val_acc: 0.8211 f1: 0.8160
[epoch  6] [step 210] train_loss: 0.0462 train_acc: 0.9449 val_loss: 0.2270 val_acc: 0.8105 f1: 0.8069
[epoch  6] [step 220] train_loss: 0.0459 train_acc: 0.9450 val_loss: 0.2218 val_acc: 0.8133 f1: 0.8076
[epoch  6] [step 221] train_loss: 0.0458 train_acc: 0.9451 val_loss: 0.2238 val_acc: 0.8116 f1: 0.8060
positive -- correct: 379  predict: 477  real: 486  f1: 0.7871
negative -- correct: 424  predict: 505  real: 522  f1: 0.8257
neutral  -- correct: 675  predict: 807  real: 781  f1: 0.8501
best_epoch: 5  best_step: 110  best_f1: 0.8210
time: 233.1612s
[epoch  7] [step  10] train_loss: 0.0175 train_acc: 0.9830 val_loss: 0.2622 val_acc: 0.8133 f1: 0.8090
[epoch  7] [step  20] train_loss: 0.0200 train_acc: 0.9792 val_loss: 0.3153 val_acc: 0.8016 f1: 0.7991
[epoch  7] [step  30] train_loss: 0.0255 train_acc: 0.9698 val_loss: 0.2567 val_acc: 0.8116 f1: 0.8064
[epoch  7] [step  40] train_loss: 0.0264 train_acc: 0.9688 val_loss: 0.2599 val_acc: 0.8144 f1: 0.8110
[epoch  7] [step  50] train_loss: 0.0281 train_acc: 0.9651 val_loss: 0.2660 val_acc: 0.7993 f1: 0.7949
[epoch  7] [step  60] train_loss: 0.0293 train_acc: 0.9641 val_loss: 0.2479 val_acc: 0.8049 f1: 0.8010
[epoch  7] [step  70] train_loss: 0.0284 train_acc: 0.9661 val_loss: 0.2612 val_acc: 0.7988 f1: 0.7944
[epoch  7] [step  80] train_loss: 0.0288 train_acc: 0.9668 val_loss: 0.2530 val_acc: 0.8032 f1: 0.7990
[epoch  7] [step  90] train_loss: 0.0292 train_acc: 0.9674 val_loss: 0.2768 val_acc: 0.8077 f1: 0.8054
[epoch  7] [step 100] train_loss: 0.0298 train_acc: 0.9666 val_loss: 0.2739 val_acc: 0.8055 f1: 0.8014
[epoch  7] [step 110] train_loss: 0.0292 train_acc: 0.9673 val_loss: 0.2976 val_acc: 0.8032 f1: 0.8008
[epoch  7] [step 120] train_loss: 0.0289 train_acc: 0.9672 val_loss: 0.2657 val_acc: 0.8122 f1: 0.8077
[epoch  7] [step 130] train_loss: 0.0293 train_acc: 0.9659 val_loss: 0.2614 val_acc: 0.8155 f1: 0.8128
[epoch  7] [step 140] train_loss: 0.0286 train_acc: 0.9670 val_loss: 0.2603 val_acc: 0.8178 f1: 0.8139
[epoch  7] [step 150] train_loss: 0.0285 train_acc: 0.9669 val_loss: 0.2807 val_acc: 0.8139 f1: 0.8090
[epoch  7] [step 160] train_loss: 0.0290 train_acc: 0.9656 val_loss: 0.2832 val_acc: 0.8133 f1: 0.8107
[epoch  7] [step 170] train_loss: 0.0303 train_acc: 0.9635 val_loss: 0.2590 val_acc: 0.8116 f1: 0.8058
[epoch  7] [step 180] train_loss: 0.0306 train_acc: 0.9629 val_loss: 0.2438 val_acc: 0.8111 f1: 0.8058
[epoch  7] [step 190] train_loss: 0.0310 train_acc: 0.9620 val_loss: 0.2490 val_acc: 0.8144 f1: 0.8096
[epoch  7] [step 200] train_loss: 0.0319 train_acc: 0.9605 val_loss: 0.2298 val_acc: 0.8178 f1: 0.8130
[epoch  7] [step 210] train_loss: 0.0322 train_acc: 0.9599 val_loss: 0.2339 val_acc: 0.8144 f1: 0.8076
[epoch  7] [step 220] train_loss: 0.0323 train_acc: 0.9603 val_loss: 0.2397 val_acc: 0.8195 f1: 0.8163
[epoch  7] [step 221] train_loss: 0.0322 train_acc: 0.9604 val_loss: 0.2420 val_acc: 0.8155 f1: 0.8124
positive -- correct: 379  predict: 477  real: 486  f1: 0.7871
negative -- correct: 424  predict: 505  real: 522  f1: 0.8257
neutral  -- correct: 675  predict: 807  real: 781  f1: 0.8501
best_epoch: 5  best_step: 110  best_f1: 0.8210
time: 233.9264s
[epoch  8] [step  10] train_loss: 0.0251 train_acc: 0.9801 val_loss: 0.2628 val_acc: 0.8094 f1: 0.8042
[epoch  8] [step  20] train_loss: 0.0301 train_acc: 0.9673 val_loss: 0.2571 val_acc: 0.8133 f1: 0.8101
[epoch  8] [step  30] train_loss: 0.0272 train_acc: 0.9698 val_loss: 0.2584 val_acc: 0.8183 f1: 0.8152
[epoch  8] [step  40] train_loss: 0.0256 train_acc: 0.9726 val_loss: 0.2672 val_acc: 0.8228 f1: 0.8190
[epoch  8] [step  50] train_loss: 0.0255 train_acc: 0.9730 val_loss: 0.2675 val_acc: 0.8183 f1: 0.8141
[epoch  8] [step  60] train_loss: 0.0235 train_acc: 0.9739 val_loss: 0.2793 val_acc: 0.8161 f1: 0.8116
[epoch  8] [step  70] train_loss: 0.0236 train_acc: 0.9727 val_loss: 0.2849 val_acc: 0.8066 f1: 0.8014
[epoch  8] [step  80] train_loss: 0.0237 train_acc: 0.9718 val_loss: 0.2834 val_acc: 0.8055 f1: 0.8015
[epoch  8] [step  90] train_loss: 0.0237 train_acc: 0.9715 val_loss: 0.2822 val_acc: 0.8122 f1: 0.8092
[epoch  8] [step 100] train_loss: 0.0238 train_acc: 0.9715 val_loss: 0.2659 val_acc: 0.8161 f1: 0.8112
[epoch  8] [step 110] train_loss: 0.0227 train_acc: 0.9733 val_loss: 0.3181 val_acc: 0.8049 f1: 0.8029
[epoch  8] [step 120] train_loss: 0.0230 train_acc: 0.9731 val_loss: 0.3012 val_acc: 0.8094 f1: 0.8050
[epoch  8] [step 130] train_loss: 0.0245 train_acc: 0.9711 val_loss: 0.2849 val_acc: 0.8133 f1: 0.8079
[epoch  8] [step 140] train_loss: 0.0251 train_acc: 0.9707 val_loss: 0.2690 val_acc: 0.8139 f1: 0.8072
[epoch  8] [step 150] train_loss: 0.0247 train_acc: 0.9710 val_loss: 0.2837 val_acc: 0.8139 f1: 0.8089
[epoch  8] [step 160] train_loss: 0.0243 train_acc: 0.9713 val_loss: 0.3041 val_acc: 0.8083 f1: 0.8057
[epoch  8] [step 170] train_loss: 0.0242 train_acc: 0.9711 val_loss: 0.2816 val_acc: 0.8105 f1: 0.8051
[epoch  8] [step 180] train_loss: 0.0241 train_acc: 0.9712 val_loss: 0.2761 val_acc: 0.8139 f1: 0.8097
[epoch  8] [step 190] train_loss: 0.0241 train_acc: 0.9712 val_loss: 0.2851 val_acc: 0.8122 f1: 0.8076
[epoch  8] [step 200] train_loss: 0.0249 train_acc: 0.9703 val_loss: 0.2646 val_acc: 0.8139 f1: 0.8100
[epoch  8] [step 210] train_loss: 0.0248 train_acc: 0.9704 val_loss: 0.2740 val_acc: 0.8139 f1: 0.8090
[epoch  8] [step 220] train_loss: 0.0252 train_acc: 0.9702 val_loss: 0.2923 val_acc: 0.8088 f1: 0.8053
[epoch  8] [step 221] train_loss: 0.0253 train_acc: 0.9701 val_loss: 0.2950 val_acc: 0.8088 f1: 0.8057
positive -- correct: 379  predict: 477  real: 486  f1: 0.7871
negative -- correct: 424  predict: 505  real: 522  f1: 0.8257
neutral  -- correct: 675  predict: 807  real: 781  f1: 0.8501
best_epoch: 5  best_step: 110  best_f1: 0.8210
time: 225.8182s
[epoch  9] [step  10] train_loss: 0.0212 train_acc: 0.9716 val_loss: 0.2737 val_acc: 0.8200 f1: 0.8137
[epoch  9] [step  20] train_loss: 0.0187 train_acc: 0.9762 val_loss: 0.2884 val_acc: 0.8206 f1: 0.8161
[epoch  9] [step  30] train_loss: 0.0199 train_acc: 0.9738 val_loss: 0.3037 val_acc: 0.8167 f1: 0.8121
[epoch  9] [step  40] train_loss: 0.0195 train_acc: 0.9748 val_loss: 0.3160 val_acc: 0.8105 f1: 0.8075
[epoch  9] [step  50] train_loss: 0.0206 train_acc: 0.9755 val_loss: 0.3134 val_acc: 0.8083 f1: 0.8010
[epoch  9] [step  60] train_loss: 0.0204 train_acc: 0.9749 val_loss: 0.3075 val_acc: 0.8133 f1: 0.8081
[epoch  9] [step  70] train_loss: 0.0197 train_acc: 0.9758 val_loss: 0.3133 val_acc: 0.8155 f1: 0.8108
[epoch  9] [step  80] train_loss: 0.0189 train_acc: 0.9776 val_loss: 0.3072 val_acc: 0.8155 f1: 0.8095
[epoch  9] [step  90] train_loss: 0.0184 train_acc: 0.9780 val_loss: 0.3121 val_acc: 0.8144 f1: 0.8094
[epoch  9] [step 100] train_loss: 0.0181 train_acc: 0.9774 val_loss: 0.3184 val_acc: 0.8105 f1: 0.8060
[epoch  9] [step 110] train_loss: 0.0182 train_acc: 0.9789 val_loss: 0.3174 val_acc: 0.8122 f1: 0.8058
[epoch  9] [step 120] train_loss: 0.0186 train_acc: 0.9786 val_loss: 0.3249 val_acc: 0.8116 f1: 0.8061
[epoch  9] [step 130] train_loss: 0.0183 train_acc: 0.9792 val_loss: 0.3220 val_acc: 0.8144 f1: 0.8096
[epoch  9] [step 140] train_loss: 0.0185 train_acc: 0.9789 val_loss: 0.3442 val_acc: 0.8127 f1: 0.8054
[epoch  9] [step 150] train_loss: 0.0193 train_acc: 0.9783 val_loss: 0.2929 val_acc: 0.8161 f1: 0.8125
[epoch  9] [step 160] train_loss: 0.0190 train_acc: 0.9785 val_loss: 0.2792 val_acc: 0.8144 f1: 0.8105
[epoch  9] [step 170] train_loss: 0.0193 train_acc: 0.9779 val_loss: 0.2790 val_acc: 0.8195 f1: 0.8142
[epoch  9] [step 180] train_loss: 0.0195 train_acc: 0.9777 val_loss: 0.3077 val_acc: 0.8077 f1: 0.8044
[epoch  9] [step 190] train_loss: 0.0191 train_acc: 0.9781 val_loss: 0.3310 val_acc: 0.8038 f1: 0.8011
[epoch  9] [step 200] train_loss: 0.0200 train_acc: 0.9776 val_loss: 0.2908 val_acc: 0.8189 f1: 0.8146
[epoch  9] [step 210] train_loss: 0.0210 train_acc: 0.9772 val_loss: 0.2876 val_acc: 0.8083 f1: 0.8035
[epoch  9] [step 220] train_loss: 0.0209 train_acc: 0.9772 val_loss: 0.2591 val_acc: 0.8200 f1: 0.8150
[epoch  9] [step 221] train_loss: 0.0209 train_acc: 0.9773 val_loss: 0.2586 val_acc: 0.8172 f1: 0.8120
positive -- correct: 379  predict: 477  real: 486  f1: 0.7871
negative -- correct: 424  predict: 505  real: 522  f1: 0.8257
neutral  -- correct: 675  predict: 807  real: 781  f1: 0.8501
best_epoch: 5  best_step: 110  best_f1: 0.8210
time: 220.5454s
max_val_accuracy: 0.8261598658468418
